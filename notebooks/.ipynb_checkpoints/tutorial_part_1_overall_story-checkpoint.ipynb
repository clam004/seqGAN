{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.insert(1, '../')\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "\n",
    "from models import generator\n",
    "from models import discriminator\n",
    "from trainers import train_generator_MLE, train_generator_PG, train_discriminator\n",
    "import helpers\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial Part 1 Overall Story\n",
    "\n",
    "here we will describe each step of the pipeline at a high level to help us contextualize our future learnings\n",
    "\n",
    "\n",
    "## Synthetic Data Experiment\n",
    "\n",
    "The most accurate way of evaluating generative models is that we draw some samples from it and let human observers re- view them based on their prior knowledge. We assume that the human observer has learned an accurate model of the natural distribution p_human(x). \n",
    " \n",
    "the authots used a randomly initialized language model as the true model, aka, the ***oracle***, to generate the \"real\" data distribution p(x_t |x_1 , . . . , x_t−1 ). The benefit of having such oracle is that firstly, it provides the training dataset and secondly evaluates the exact perfor- mance of the generative models, which will not be possible with real data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# experimental constants\n",
    "\n",
    "CUDA = torch.cuda.is_available()\n",
    "VOCAB_SIZE = 5000\n",
    "MAX_SEQ_LEN = 20\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "START_LETTER = 0\n",
    "\n",
    "GEN_EMBEDDING_DIM = 32 # length of input vectors for generator and oracle\n",
    "GEN_HIDDEN_DIM = 32 # length of hidden state for generator and oracle\n",
    "\n",
    "oracle_state_dict_path = '../params/oracle_EMBDIM32_HIDDENDIM32_VOCAB5000_MAXSEQLEN20.trc'\n",
    "oracle_samples_path = '../sample_data/oracle_samples.trc'\n",
    "\n",
    "\n",
    "MLE_TRAIN_EPOCHS = 100\n",
    "ADV_TRAIN_EPOCHS = 50\n",
    "POS_NEG_SAMPLES = 10000\n",
    "\n",
    "DIS_EMBEDDING_DIM = 64 # length of input vectors for discriminator\n",
    "DIS_HIDDEN_DIM = 64 # length of hidden state for discriminator\n",
    "\n",
    "pretrained_gen_path = '../params/gen_MLEtrain_EMBDIM32_HIDDENDIM32_VOCAB5000_MAXSEQLEN20.trc'\n",
    "pretrained_dis_path = '../params/dis_pretrain_EMBDIM_64_HIDDENDIM64_VOCAB5000_MAXSEQLEN20.trc'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Generator(\n",
       "  (embeddings): Embedding(5000, 32)\n",
       "  (gru): GRU(32, 32)\n",
       "  (gru2out): Linear(in_features=32, out_features=5000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oracle = generator.Generator(\n",
    "    GEN_EMBEDDING_DIM, \n",
    "    GEN_HIDDEN_DIM, \n",
    "    VOCAB_SIZE, \n",
    "    MAX_SEQ_LEN, \n",
    "    gpu=CUDA\n",
    ")\n",
    "\n",
    "# for reproducibiility we provide saved parameters for the oracle\n",
    "oracle.load_state_dict(torch.load(oracle_state_dict_path))\n",
    "\n",
    "oracle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output above should look like this\n",
    "\n",
    "```\n",
    "Generator(\n",
    "  (embeddings): Embedding(5000, 32)\n",
    "  (gru): GRU(32, 32)\n",
    "  (gru2out): Linear(in_features=32, out_features=5000, bias=True)\n",
    ")\n",
    "```\n",
    "\n",
    "To explain the information above: the model has 5000 possible input vectors in its vocab each with length 32, the GRU takes vectors  length 32 and outputs activation of the same length. The output returns activations of the same length as the vocab.\n",
    "\n",
    "the authors use the oracle to generate 10,000 sequences of length 20 as the training set S for the generative models.\n",
    "we have already used helpers.batchwise_sample() to save S so you can load it below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'> torch.Size([10000, 20])\n"
     ]
    }
   ],
   "source": [
    "oracle_samples = torch.load(oracle_samples_path).type(torch.LongTensor)\n",
    "print(type(oracle_samples), oracle_samples.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### instantiate a generator and discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen = generator.Generator(\n",
    "    GEN_EMBEDDING_DIM, \n",
    "    GEN_HIDDEN_DIM, \n",
    "    VOCAB_SIZE, \n",
    "    MAX_SEQ_LEN, \n",
    "    gpu=CUDA,\n",
    ")\n",
    "\n",
    "dis = discriminator.Discriminator(\n",
    "    DIS_EMBEDDING_DIM, \n",
    "    DIS_HIDDEN_DIM, \n",
    "    VOCAB_SIZE,\n",
    "    MAX_SEQ_LEN, \n",
    "    gpu=CUDA,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Generator(\n",
       "  (embeddings): Embedding(5000, 32)\n",
       "  (gru): GRU(32, 32)\n",
       "  (gru2out): Linear(in_features=32, out_features=5000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Discriminator(\n",
       "  (embeddings): Embedding(5000, 64)\n",
       "  (gru): GRU(64, 64, num_layers=2, dropout=0.2, bidirectional=True)\n",
       "  (gru2hidden): Linear(in_features=256, out_features=64, bias=True)\n",
       "  (dropout_linear): Dropout(p=0.2, inplace=False)\n",
       "  (hidden2out): Linear(in_features=64, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### If you have and want to use GPU, all models and model inputs need to be on GPU\n",
    "\n",
    "If there is any mismatch between the parameters being on one device and the inputs being on another, then problems will arise. We run one call to the helpers.batchwise_oracle_nll\n",
    "function to test that we have the inputs and params on mathing devices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 GeForce GTX 1080 Ti\n",
      "cuda:0 cuda:0 cuda:0\n"
     ]
    }
   ],
   "source": [
    "if CUDA:\n",
    "    oracle = oracle.cuda()\n",
    "    gen = gen.cuda()\n",
    "    dis = dis.cuda()\n",
    "    oracle_samples = oracle_samples.cuda()\n",
    "    \n",
    "    print(torch.cuda.device_count(), torch.cuda.get_device_name(0))\n",
    "    \n",
    "    print(\n",
    "    next(gen.embeddings.parameters()).device, \n",
    "    next(dis.embeddings.parameters()).device,\n",
    "    next(oracle.embeddings.parameters()).device,\n",
    "     )\n",
    "    \n",
    "# sample from generator and compute oracle NLL\n",
    "oracle_loss = helpers.batchwise_oracle_nll(\n",
    "    gen, \n",
    "    oracle, \n",
    "    POS_NEG_SAMPLES, \n",
    "    BATCH_SIZE, MAX_SEQ_LEN,\n",
    "    start_letter=START_LETTER, \n",
    "    gpu=CUDA,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GENERATOR MLE TRAINING\n",
    "\n",
    "At the beginning of the training, the authors used maximum likelihood estimation (MLE) to pretrain Gθ on training set S. \n",
    "\n",
    "They found the supervised signal from the pretrained discriminator is informative to help adjust the generator efficiently.\n",
    "\n",
    "```\n",
    "# GENERATOR MLE TRAINING\n",
    "print('Starting Generator MLE Training...')\n",
    "gen_optimizer = optim.Adam(gen.parameters(), lr=1e-2)\n",
    "train_generator_MLE(gen, gen_optimizer, oracle, oracle_samples, MLE_TRAIN_EPOCHS)\n",
    "torch.save(gen.state_dict(), pretrained_gen_path)\n",
    "\n",
    "# PRETRAIN DISCRIMINATOR\n",
    "print('Starting Discriminator Training...')\n",
    "dis_optimizer = optim.Adagrad(dis.parameters())\n",
    "train_discriminator(dis, dis_optimizer, oracle_samples, gen, oracle, d_steps = 50,  epochs = 3)\n",
    "torch.save(dis.state_dict(), pretrained_dis_path)\n",
    "```\n",
    "\n",
    "The below pretraining only needs to be done once. After it is saved, it can be loaded using `model.load_state_dict(torch.load(pretrained_gen_path))` in the cell two cells down while skipping the next two cells\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Generator MLE Training...\n",
      "epoch 1 : .......... average_train_NLL = 6.8282, oracle_sample_NLL = 14.6160\n",
      "epoch 2 : .......... average_train_NLL = 6.1780, oracle_sample_NLL = 13.7436\n",
      "epoch 3 : .......... average_train_NLL = 5.8610, oracle_sample_NLL = 13.1479\n",
      "epoch 4 : .......... average_train_NLL = 5.6560, oracle_sample_NLL = 12.8644\n",
      "epoch 5 : .......... average_train_NLL = 5.5087, oracle_sample_NLL = 12.5425\n",
      "epoch 6 : .......... average_train_NLL = 5.3974, oracle_sample_NLL = 12.3266\n",
      "epoch 7 : .......... average_train_NLL = 5.3087, oracle_sample_NLL = 12.1899\n",
      "epoch 8 : .......... average_train_NLL = 5.2363, oracle_sample_NLL = 12.0750\n",
      "epoch 9 : .......... average_train_NLL = 5.1747, oracle_sample_NLL = 11.9395\n",
      "epoch 10 : .......... average_train_NLL = 5.1223, oracle_sample_NLL = 11.8729\n",
      "epoch 11 : .......... average_train_NLL = 5.0776, oracle_sample_NLL = 11.8209\n",
      "epoch 12 : .......... average_train_NLL = 5.0383, oracle_sample_NLL = 11.7077\n",
      "epoch 13 : .......... average_train_NLL = 5.0031, oracle_sample_NLL = 11.6678\n",
      "epoch 14 : .......... average_train_NLL = 4.9722, oracle_sample_NLL = 11.5674\n",
      "epoch 15 : .......... average_train_NLL = 4.9448, oracle_sample_NLL = 11.5367\n",
      "epoch 16 : .......... average_train_NLL = 4.9199, oracle_sample_NLL = 11.4842\n",
      "epoch 17 : .......... average_train_NLL = 4.8971, oracle_sample_NLL = 11.5041\n",
      "epoch 18 : .......... average_train_NLL = 4.8772, oracle_sample_NLL = 11.4346\n",
      "epoch 19 : .......... average_train_NLL = 4.8570, oracle_sample_NLL = 11.4180\n",
      "epoch 20 : .......... average_train_NLL = 4.8420, oracle_sample_NLL = 11.3818\n",
      "epoch 21 : .......... average_train_NLL = 4.8253, oracle_sample_NLL = 11.3583\n",
      "epoch 22 : .......... average_train_NLL = 4.8114, oracle_sample_NLL = 11.3381\n",
      "epoch 23 : .......... average_train_NLL = 4.7979, oracle_sample_NLL = 11.2928\n",
      "epoch 24 : .......... average_train_NLL = 4.7840, oracle_sample_NLL = 11.2967\n",
      "epoch 25 : .......... average_train_NLL = 4.7722, oracle_sample_NLL = 11.2697\n",
      "epoch 26 : .......... average_train_NLL = 4.7633, oracle_sample_NLL = 11.2715\n",
      "epoch 27 : .......... average_train_NLL = 4.7525, oracle_sample_NLL = 11.2292\n",
      "epoch 28 : .......... average_train_NLL = 4.7441, oracle_sample_NLL = 11.2136\n",
      "epoch 29 : .......... average_train_NLL = 4.7346, oracle_sample_NLL = 11.2128\n",
      "epoch 30 : .......... average_train_NLL = 4.7258, oracle_sample_NLL = 11.1949\n",
      "epoch 31 : .......... average_train_NLL = 4.7178, oracle_sample_NLL = 11.1940\n",
      "epoch 32 : .......... average_train_NLL = 4.7085, oracle_sample_NLL = 11.1875\n",
      "epoch 33 : .......... average_train_NLL = 4.7041, oracle_sample_NLL = 11.1756\n",
      "epoch 34 : .......... average_train_NLL = 4.6953, oracle_sample_NLL = 11.1604\n",
      "epoch 35 : .......... average_train_NLL = 4.6908, oracle_sample_NLL = 11.1249\n",
      "epoch 36 : .......... average_train_NLL = 4.6830, oracle_sample_NLL = 11.1920\n",
      "epoch 37 : .......... average_train_NLL = 4.6793, oracle_sample_NLL = 11.1615\n",
      "epoch 38 : .......... average_train_NLL = 4.6713, oracle_sample_NLL = 11.1487\n",
      "epoch 39 : .......... average_train_NLL = 4.6641, oracle_sample_NLL = 11.0967\n",
      "epoch 40 : .......... average_train_NLL = 4.6587, oracle_sample_NLL = 11.1435\n",
      "epoch 41 : .......... average_train_NLL = 4.6581, oracle_sample_NLL = 11.1504\n",
      "epoch 42 : .......... average_train_NLL = 4.6557, oracle_sample_NLL = 11.0924\n",
      "epoch 43 : .......... average_train_NLL = 4.6442, oracle_sample_NLL = 11.0939\n",
      "epoch 44 : .......... average_train_NLL = 4.6413, oracle_sample_NLL = 11.0904\n",
      "epoch 45 : .......... average_train_NLL = 4.6350, oracle_sample_NLL = 11.1227\n",
      "epoch 46 : .......... average_train_NLL = 4.6360, oracle_sample_NLL = 11.0930\n",
      "epoch 47 : .......... average_train_NLL = 4.6324, oracle_sample_NLL = 11.0728\n",
      "epoch 48 : .......... average_train_NLL = 4.6271, oracle_sample_NLL = 11.0899\n",
      "epoch 49 : .......... average_train_NLL = 4.6214, oracle_sample_NLL = 11.0461\n",
      "epoch 50 : .......... average_train_NLL = 4.6182, oracle_sample_NLL = 11.0488\n",
      "epoch 51 : .......... average_train_NLL = 4.6208, oracle_sample_NLL = 11.1194\n",
      "epoch 52 : .......... average_train_NLL = 4.6134, oracle_sample_NLL = 11.0896\n",
      "epoch 53 : .......... average_train_NLL = 4.6083, oracle_sample_NLL = 11.0824\n",
      "epoch 54 : .......... average_train_NLL = 4.6047, oracle_sample_NLL = 11.0207\n",
      "epoch 55 : .......... average_train_NLL = 4.6029, oracle_sample_NLL = 11.0760\n",
      "epoch 56 : .......... average_train_NLL = 4.5962, oracle_sample_NLL = 11.0465\n",
      "epoch 57 : .......... average_train_NLL = 4.5984, oracle_sample_NLL = 11.0643\n",
      "epoch 58 : .......... average_train_NLL = 4.5932, oracle_sample_NLL = 11.0679\n",
      "epoch 59 : .......... average_train_NLL = 4.5862, oracle_sample_NLL = 11.0694\n",
      "epoch 60 : .......... average_train_NLL = 4.5828, oracle_sample_NLL = 11.0863\n",
      "epoch 61 : .......... average_train_NLL = 4.5823, oracle_sample_NLL = 11.0437\n",
      "epoch 62 : .......... average_train_NLL = 4.5846, oracle_sample_NLL = 11.0391\n",
      "epoch 63 : .......... average_train_NLL = 4.5784, oracle_sample_NLL = 11.0437\n",
      "epoch 64 : .......... average_train_NLL = 4.5776, oracle_sample_NLL = 11.0643\n",
      "epoch 65 : .......... average_train_NLL = 4.5773, oracle_sample_NLL = 11.0481\n",
      "epoch 66 : .......... average_train_NLL = 4.5728, oracle_sample_NLL = 11.0131\n",
      "epoch 67 : .......... average_train_NLL = 4.5712, oracle_sample_NLL = 11.0715\n",
      "epoch 68 : .......... average_train_NLL = 4.5695, oracle_sample_NLL = 11.0328\n",
      "epoch 69 : .......... average_train_NLL = 4.5669, oracle_sample_NLL = 11.0216\n",
      "epoch 70 : .......... average_train_NLL = 4.5602, oracle_sample_NLL = 11.0316\n",
      "epoch 71 : .......... average_train_NLL = 4.5619, oracle_sample_NLL = 10.9854\n",
      "epoch 72 : .......... average_train_NLL = 4.5612, oracle_sample_NLL = 11.0086\n",
      "epoch 73 : .......... average_train_NLL = 4.5794, oracle_sample_NLL = 11.0488\n",
      "epoch 74 : .......... average_train_NLL = 4.5559, oracle_sample_NLL = 10.9845\n",
      "epoch 75 : .......... average_train_NLL = 4.5568, oracle_sample_NLL = 10.9918\n",
      "epoch 76 : .......... average_train_NLL = 4.5527, oracle_sample_NLL = 10.9917\n",
      "epoch 77 : .......... average_train_NLL = 4.5528, oracle_sample_NLL = 10.9918\n",
      "epoch 78 : .......... average_train_NLL = 4.5539, oracle_sample_NLL = 10.9771\n",
      "epoch 79 : .......... average_train_NLL = 4.5429, oracle_sample_NLL = 10.9805\n",
      "epoch 80 : .......... average_train_NLL = 4.5412, oracle_sample_NLL = 10.9624\n",
      "epoch 81 : .......... average_train_NLL = 4.5406, oracle_sample_NLL = 10.9655\n",
      "epoch 82 : .......... average_train_NLL = 4.5381, oracle_sample_NLL = 10.9985\n",
      "epoch 83 : .......... average_train_NLL = 4.5443, oracle_sample_NLL = 10.9729\n",
      "epoch 84 : .......... average_train_NLL = 4.5395, oracle_sample_NLL = 10.9439\n",
      "epoch 85 : .......... average_train_NLL = 4.5384, oracle_sample_NLL = 10.9812\n",
      "epoch 86 : .......... average_train_NLL = 4.5381, oracle_sample_NLL = 10.9694\n",
      "epoch 87 : .......... average_train_NLL = 4.5347, oracle_sample_NLL = 10.9605\n",
      "epoch 88 : .......... average_train_NLL = 4.5463, oracle_sample_NLL = 10.9484\n",
      "epoch 89 : .......... average_train_NLL = 4.5331, oracle_sample_NLL = 10.9364\n",
      "epoch 90 : .......... average_train_NLL = 4.5292, oracle_sample_NLL = 10.9737\n",
      "epoch 91 : .......... average_train_NLL = 4.5300, oracle_sample_NLL = 10.9442\n",
      "epoch 92 : .......... average_train_NLL = 4.5254, oracle_sample_NLL = 10.9750\n",
      "epoch 93 : .......... average_train_NLL = 4.5268, oracle_sample_NLL = 10.9237\n",
      "epoch 94 : .......... average_train_NLL = 4.5202, oracle_sample_NLL = 10.9857\n",
      "epoch 95 : .......... average_train_NLL = 4.5195, oracle_sample_NLL = 10.9686\n",
      "epoch 96 : .......... average_train_NLL = 4.5234, oracle_sample_NLL = 10.9461\n",
      "epoch 97 : .......... average_train_NLL = 4.5213, oracle_sample_NLL = 10.9139\n",
      "epoch 98 : .......... average_train_NLL = 4.5194, oracle_sample_NLL = 10.9230\n",
      "epoch 99 : .......... average_train_NLL = 4.5298, oracle_sample_NLL = 10.9627\n",
      "epoch 100 : .......... average_train_NLL = 4.5203, oracle_sample_NLL = 10.9189\n"
     ]
    }
   ],
   "source": [
    "# GENERATOR MLE TRAINING\n",
    "print('Starting Generator MLE Training...')\n",
    "gen_optimizer = optim.Adam(gen.parameters(), lr=1e-2)\n",
    "train_generator_MLE(gen, gen_optimizer, oracle, oracle_samples, \n",
    "                    MLE_TRAIN_EPOCHS, \n",
    "                    POS_NEG_SAMPLES = POS_NEG_SAMPLES,\n",
    "                    BATCH_SIZE = BATCH_SIZE,\n",
    "                    START_LETTER = START_LETTER,\n",
    "                    MAX_SEQ_LEN = MAX_SEQ_LEN,\n",
    "                    CUDA = CUDA,\n",
    ")\n",
    "torch.save(gen.state_dict(), pretrained_gen_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_gen_path_cpu = '../params/gen_MLEtrain_EMBDIM32_HIDDENDIM32_VOCAB5000_MAXSEQLEN20_cpu.trc'\n",
    "\n",
    "torch.save(gen.cpu().state_dict(), pretrained_gen_path_cpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Discriminator Training...\n",
      "d-step 1 epoch 1 : input.is_cuda False\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Input, output and indices must be on the current device",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-6fb82a91dbd9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Starting Discriminator Training...'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdis_optimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdagrad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mtrain_discriminator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdis_optimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moracle_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moracle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md_steps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpretrained_dis_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Projects/seqGAN/trainers.py\u001b[0m in \u001b[0;36mtrain_discriminator\u001b[0;34m(discriminator, dis_opt, real_data_samples, generator, oracle, d_steps, epochs, POS_NEG_SAMPLES, BATCH_SIZE, CUDA)\u001b[0m\n\u001b[1;32m    120\u001b[0m                 \u001b[0minp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdis_inp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdis_target\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m                 \u001b[0mdis_opt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m                 \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdiscriminator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatchClassify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m                 \u001b[0mloss_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBCELoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Projects/seqGAN/models/discriminator.py\u001b[0m in \u001b[0;36mbatchClassify\u001b[0;34m(self, inp)\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit_hidden\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Projects/seqGAN/models/discriminator.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hidden)\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'input.is_cuda'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_cuda\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0;31m# input dim                                                # batch_size x seq_len\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m         \u001b[0memb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m                               \u001b[0;31m# batch_size x seq_len x embedding_dim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m         \u001b[0memb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0memb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m                                 \u001b[0;31m# seq_len x batch_size x embedding_dim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgru\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0memb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m                          \u001b[0;31m# 4 x batch_size x hidden_dim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/sparse.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    124\u001b[0m         return F.embedding(\n\u001b[1;32m    125\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m             self.norm_type, self.scale_grad_by_freq, self.sparse)\n\u001b[0m\u001b[1;32m    127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36membedding\u001b[0;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[1;32m   1850\u001b[0m         \u001b[0;31m# remove once script supports set_grad_enabled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1851\u001b[0m         \u001b[0m_no_grad_embedding_renorm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1852\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale_grad_by_freq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msparse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1853\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1854\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Input, output and indices must be on the current device"
     ]
    }
   ],
   "source": [
    "# PRETRAIN DISCRIMINATOR\n",
    "print('Starting Discriminator Training...')\n",
    "dis_optimizer = optim.Adagrad(dis.parameters())\n",
    "train_discriminator(dis, dis_optimizer, oracle_samples, gen, oracle, \n",
    "                    d_steps = 50,  \n",
    "                    epochs = 3,\n",
    "                    POS_NEG_SAMPLES = POS_NEG_SAMPLES,\n",
    "                    BATCH_SIZE = BATCH_SIZE,\n",
    "                    CUDA = CUDA,\n",
    ")\n",
    "torch.save(dis.state_dict(), pretrained_dis_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load pretrained generator and discrimnator\n",
    "gen.load_state_dict(torch.load(pretrained_gen_path))\n",
    "dis.load_state_dict(torch.load(pretrained_dis_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
